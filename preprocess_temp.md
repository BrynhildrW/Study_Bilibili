---
html:
    toc: true
print_background: true
---

# EEG-BCI 信号处理基本流程
这是特地为 *CLeaR* 与已通关“羊了个羊”（~~垃圾游戏~~）的 *AAA活鱼宰杀甄姐* 临时新增的教程页面，后续考虑进一步扩增完善，并增添至 FlowUs 主页中。

临时插入一个广告，强烈推荐 Snipaste（如果你们不知道的话），这个小软件可以极大程度地改善你们阅读电子文档的体验感。

一个经典 SSVEP-BCI 系统的工作原理示意图如下所示：

![40指令集SSVEP-BCI系统示意图](/figures/JFPM.jpeg)

子图 A 展示的是系统流程示意图，包括刺激显示、信号采集、预处理、特征提取（训练模型）、分类识别以及视/听觉反馈。我们目前主要进行的代码工作是**预处理**、**模型训练**以及**分类识别**这三个部分。至于子图 B 和 C 是留给你们的作业，等我哪天想起来会向你们提问的，请务必（对着论文）看懂这两张图都是什么意思。

论文原文链接

## 预处理
基于 Python 语言的 EEG 数据预处理步骤如下图所示.接下来每一步的说明过程中，我会随机提出一些问题（前缀为 **Q**），请根据我提供的代码文件以及 MNE 官网的 API 说明思考答案。

![python预处理步骤](/figures/preprocessing.png)

### 定位 .cnt 文件
实验室通常使用 NeuroScan 公司生产的仪器设备采集数据，因此原始数据文件后缀为 .cnt。一般情况下，我们推荐的数据存储格式（文件层级顺序）为：“实验名\时间-受试者\xxx.cnt”。换句话说，单个受试者数据文件夹中存在多个 .cnt 文件：

**Q1.** 为什么需要分别存储多个 .cnt 文件？这些文件在数据格式或内容上存在重大差别吗？

这个部分的代码是我初次接触 Python 时仿制的，很久很久以前的“不成熟产品”，有点祖传“屎山”的感觉（~~真的只有这部分是这样~~）。因为实际操作过程中，我们一般不需要把所有被试的数据统一塞到内存中去处理，通过循环操作完全可以达到更快的运行速度。你们可能听过一句话叫“空间换时间”，这句话其实并不绝对。因为操作系统把数据从硬盘读取、写入内存的这个步骤也是需要耗时的。根据使用场景不同，“磨刀”耗费的时间可能已经超过了直接上手“砍柴”。

这也是给你们提个醒，虽然你们经常看到某些教程让你们“少写循环”，甚至有些不负责任的教程盲目追求 *Pythonic*，即简洁编程，力求一行代码解决问题。这种代码有时候并没有循环运行速度快，一切以实际测试结果为准，不要盲听盲信。作为初学者，循环能够帮助你们理解问题的本质与运行过程。先写个准确的循环，再考虑精简代码结构。
***

### 读取数据文件
如果你们查阅 MNE 官网的[教程][teach1]，可以看到不同数据格式（源于不同采集设备）的读取方法，各函数的命名也比较直接，基本上都是`read_raw_xxx()`，.cnt 的关键读取函数即为`mne.io.read_raw_cnt()`：

**Q2.** `mne.io.read_raw_cnt()`的主要输入参数有哪些，它们分别具有什么含义？

执行单次`mne.io.read_raw_cnt()`可将单个 .cnt 文件中的数据信息读取为 `mne.Raw` 类。这个类最重要、也是区分于 MNE 的其它自定义类的特点，就是其中的数据是**完全连续的**（请务必记住这一点，后面有问题涉及到相关知识）。我们当然可以分别处理每个 .cnt 文件，并在程序的最后将矩阵统一拼接，但是这样效率很低：

**Q3.** 如何通过`os`的路径管理批量读取来自同一被试的多个 .cnt 文件？读取后的多个`mne.Raw`类如何合并？

一个良好的编程习惯是及时清理无用变量。在调试代码块时，这样有助于让 Spyder 右上角的变量浏览区变得更清晰明了。这里需要注意一个细节：

即便使用 `del` 函数清理了某些大变量，当你点开任务管理器（`win+x`后按`t`）会发现，Python（或某个 IDE）的内存占用很可能并不会变小。这是因为 Python 的内存管理机制并没有那么“硬核”，它只是告诉操作系统，“内存中这块区域存储的东西我不要了”，本质上是删除了链接到对应内存空间的索引。如果其它应用程序（通常由 C 等其它相对底层的语言编写）没有申请新的内存空间，或 IDE 仍未关闭时，这部分占用是不会还给操作系统的。在部分对运存容量考验较大的应用场景下，需要使用`collect`库回收未指定索引的内存空间，以真正意义上实现空间的最高效利用；
***

### 提取事件标签
events 是脑电实验中非常重要的信息，可以说缺失 events 的 EEG 数据毫无价值。提取`mne.Raw`中事件（标签）信息的函数是`mne.events_from_annotations()`。除了必须传入一个`mne.Raw`类以外，该函数还有一个至关重要的参数`map`：

**Q4.** `map`参数的作用是什么？它是什么数据结构？如果不传入`map`，处理流程一定会出错吗？
***

### 重采样（非必需）
重采样（一般仅使用降采样）技术通常用于减少运算量。本课题的数据来源均为实验室环境或离线场景，算力充足，且 SSVEP 受运动伪迹影响较小（无需 ICA 等预处理步骤），因此通常不需要使用降采样处理数据。这里需要注意三点：

（1）降采样除了加快运算速度，还可以硬性地减少高频噪声。在部分对噪声比较敏感的预处理步骤（如 ICA）中，降采样后处理结果可能比原始结果更好。当然这些步骤在 SSVEP-BCI 分析中通常是不需要的；

（2）降采样需要为`mne.Raw.resample()`传入低于原始采样频率的目标频率，这个函数是`mne.Raw`的类方法，它并不会返回一个`mne.Raw`的全新副本，而是在原数据基础上直接修改，因此最好对`mne.Raw`类进行深拷贝。主要方法有两种，一是`copy.deepcopy()`（需要在代码头部`import copy`或`from copy import deepcopy`）；二是类方法`mne.Raw.copy()`。以上两种途径都会返回一个原实例的深拷贝副本；

（3）根据官网 API 对`mne.Raw.resample()`的描述：
> The intended purpose of this function is primarily to speed up computations (e.g., projection calculation) when precise timing of events is not required, as downsampling raw data effectively jitters trigger timings. It is generally recommended not to epoch downsampled data, but instead epoch and then downsample, as epoching downsampled data jitters triggers.

翻译一下，官方推荐先按试次分割数据，再进行降采样。这是因为降采样的过程有可能在标签时刻上产生进位误差。事实上，`mne.Epoch`类同样存在相似的类方法`mne.Epochs.resample()`，`mne.Raw.resample()`是不推荐使用的。**然而，然而，然而**，总有个别万不得已（并非是对时间精度要求不高）的时候，必须对连续数据进行降采样操作，此时传入原始数据的`events`变量有助于提高降采样后，事件标签索引的时间精度：

**Q5.** （这个问题很难，如果你们能回答完整我会非常开心）不妨大胆设想一下（不用举例），到底是什么特殊情况需要、且只能使用`mne.Raw.resample()`对数据进行降采样？
***

### 清洗坏道数据
说是清洗坏道，其实更准确的说法应该是“筛选所需通道的数据”（通道、导联是一码事）。该过程主要使用的函数是`mne.pick_types()`，创建`mne.Raw`实例时指定的导联功能（眼电、心电、肌电等）在此时派上了用场：`mne.pick_types()`默认只保留 EEG 导联，选定为其它功能的导联会被排除。此外，在 EEG 导联中若存在需要删除的导联，需要提前指定`drop_chans`并传入为参数`exclude`：

**Q6.** `drop_chans`的数据结构是什么？

**Q7.** `mne.pick_types()`返回参数的数据结构是什么？

**Q8.** 根据导联下标，我们可以通过列表推导式获取其名称，为什么在已有下标的情况下还需要倒回去提取导联名称？
***

### 截取试次数据
这一步需要将`mne.Raw`转换为`mne.Epochs`类，以获取可横向对比的、**不连续的**、时长相等的数据片段，即试次数据。

**Q9.** 创建`mne.Epochs`实例需要传入哪些主要参数？其中`tmin`、`tmax`的数值起点是什么？

`mne.Epochs`依然是`mne`的自定义类，尽管它有很多相对实用的类方法，例如时频分析、功率谱分析、ERP 分析、脑地形图分析等等。但是对于分类算法而言，最实用的就是最简单的`numpy.ndarray`类，因此通常需要使用`mne.Epochs.get_data()`类方法提取出数据矩阵：

**Q10.** `mne.Epochs.get_data()`提取出的矩阵默认维度是什么？

通过预设空数据矩阵 + 循环赋值，可以实现完整数据的提取。对于此时的矩阵，往往还需要一步单位转化操作：

**Q11.** 单位转化的方向是什么？为什么需要这一步基于单位的数值尺度平衡操作？
***

### 时域带通滤波
这一步其实包含的信息最多，但是由于强大的`mne.filter.filter_data()`函数默认选项（~~保姆~~）帮我们料理好了各种恼人的细节，所以一切看上去都很简单。需要注意的方面有三条：

（1）FIR 滤波器与 IIR 滤波器的设计需求是完全不一样的，表现为设计方法（窗函数法、频率抽样法、切比雪夫逼近法 vs 巴特沃斯设计、切比雪夫设计、椭圆设计……）、滤波器性能（相位延迟、幅频响应、通/阻带波纹……）等诸多方面。建议在回顾信号处理相关知识的基础上，阅读官网 API 的函数说明，以更好地理解各参数的实际作用；

（2）不存在严格规定的最佳滤波方法，一切以实际效果为准。我个人偏好 FIR 滤波器，并不意味着 IIR 设计无法达到更好的效果；

（3）FIR 滤波器对于数据长度的要求高于 IIR 设计，实际应用中可能出现有效数据长度短于滤波器长度的情况：

**Q12.** 对于有效数据长度（通常指实际刺激长度）偏短的情况，有哪些办法可以让其满足 FIR 的滤波长度需求？

**Q13.** 在`mne.Epochs`截取数据阶段，为什么不推荐将参数`tmin`设为 0 甚至是正数（如 0.14）？

带通滤波除了能够减少噪声干扰以外，还可以在时域上零均值化数据序列：

**Q14.** 数据若未经过零均值化处理，在后续训练建模以及分类过程中可能会出现什么问题？

**Q15.** 既然原始数据不能直接用来分类，为什么还推荐保留一份没有经过带通滤波的原始数据副本？
***

### 检查损坏试次（非必需）
检查方法很简单，直接用肉眼观察滤波后数据的波形数值尺度，明显超过同类样本的可视为异常值，应当予以删除。关于绘图（数据可视化）的方法正在安排，会教给你们的。
***

### 导出预处理完毕的数据
这一步使用的函数是`scipy.io.savemat()`，与之对应的读取数据函数是`scipy.io.loadmat()`（通常在代码头部`import scipy.io as io`，因而简写为`io.loadmat()`）：

**Q16.** `scipy.io.savemat()`的传入参数有哪些？其中第二参数尤为重要，它是什么数据结构？

**Q17.** `scipy.io.savemat()`一次只能存储一个数据矩阵吗？

[teach1]: https://mne.tools/stable/auto_tutorials/io/20_reading_eeg_data.html